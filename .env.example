# CausalArmor Configuration
# Copy this file to .env and fill in the values.

# ---- vLLM Proxy ----
VLLM_BASE_URL=http://localhost:8000
VLLM_MODEL=google/gemma-3-12b-it
VLLM_TIMEOUT=30.0

# ---- CausalArmor Pipeline ----
CAUSAL_ARMOR_MARGIN_TAU=0.0
CAUSAL_ARMOR_MAX_LOO_BATCH=0
# Set to 0 for no limit, or a positive integer to cap concurrent LOO calls

# ---- OpenAI (for ActionProvider / SanitizerProvider) ----
OPENAI_API_KEY=
OPENAI_ACTION_MODEL=gpt-4o
OPENAI_SANITIZER_MODEL=gpt-4o-mini

# ---- Anthropic (for ActionProvider / SanitizerProvider) ----
ANTHROPIC_API_KEY=
ANTHROPIC_ACTION_MODEL=claude-sonnet-4-5-20250929
ANTHROPIC_SANITIZER_MODEL=claude-haiku-4-5-20251001

# ---- Google Gemini (for ActionProvider / SanitizerProvider) ----
GOOGLE_API_KEY=
GEMINI_ACTION_MODEL=gemini-2.5-flash
GEMINI_SANITIZER_MODEL=gemini-2.5-flash

# ---- LiteLLM (unified provider) ----
LITELLM_ACTION_MODEL=gpt-4o
LITELLM_SANITIZER_MODEL=gpt-4o-mini
LITELLM_PROXY_MODEL=text-davinci-003
